{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "324553e2",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf866e12",
   "metadata": {},
   "source": [
    "Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ad1abe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2828c2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ceec1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check for CUDA\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a426aca2",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "689ca7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from dataset import TransliterationDataset, collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4009cc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(dataset_path, batch_size=64, shuffle=True):\n",
    "    dataset = TransliterationDataset(dataset_path)\n",
    "    data_loader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=shuffle, \n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    return dataset, data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "673fca47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths\n",
    "train_path = 'dakshina_dataset_v1.0/ml/lexicons/ml.translit.sampled.train.tsv'\n",
    "val_path = 'dakshina_dataset_v1.0/ml/lexicons/ml.translit.sampled.dev.tsv'\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataset, train_loader = prepare_data(train_path, batch_size=64)\n",
    "val_dataset, val_loader = prepare_data(val_path, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204978fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "input_size = train_dataset.get_vocab_size('source')\n",
    "output_size = train_dataset.get_vocab_size('target')\n",
    "\n",
    "\n",
    "# Print vocabulary sizes\n",
    "print(f\"Source vocabulary size: {input_size}\")\n",
    "print(f\"Target vocabulary size: {output_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8e06f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "val_input_size = val_dataset.get_vocab_size('source')\n",
    "val_output_size = val_dataset.get_vocab_size('target')\n",
    "\n",
    "# Print vocabulary sizes\n",
    "print(f\"Validation - Source vocabulary size: {val_input_size}\")\n",
    "print(f\"Validation - Target vocabulary size: {val_output_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8640c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure val dataset uses the same vocabulary as training\n",
    "val_dataset.source_char_to_idx = train_dataset.source_char_to_idx\n",
    "val_dataset.source_idx_to_char = train_dataset.source_idx_to_char\n",
    "val_dataset.target_char_to_idx = train_dataset.target_char_to_idx\n",
    "val_dataset.target_idx_to_char = train_dataset.target_idx_to_char"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8455d86a",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e881045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import trange\n",
    "\n",
    "from vanilla_model import Encoder, Decoder, Seq2Seq\n",
    "from training import train, evaluate, transliterate, calculate_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f57ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(input_size, output_size, train_loader, val_loader, device, embedding_size=256, hidden_size=256, lr=0.001,\n",
    "                n_layers=1, dropout=0.2, cell_type='lstm', epochs=10, teacher_forcing_ratio=0.5, clip=1.0, patience=5):  \n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Create model\n",
    "    encoder = Encoder(\n",
    "        input_size=input_size,\n",
    "        embedding_size=embedding_size,\n",
    "        hidden_size=hidden_size,\n",
    "        n_layers=n_layers,\n",
    "        dropout=dropout,\n",
    "        cell_type=cell_type\n",
    "    ).to(device)\n",
    "    \n",
    "    decoder = Decoder(\n",
    "        output_size=output_size,\n",
    "        embedding_size=embedding_size,\n",
    "        hidden_size=hidden_size,\n",
    "        n_layers=n_layers,\n",
    "        dropout=dropout,\n",
    "        cell_type=cell_type\n",
    "    ).to(device)\n",
    "    \n",
    "    model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "    \n",
    "    # Define optimizer and loss function\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    # # Define learning rate scheduler\n",
    "    # scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=train_dataset.target_char_to_idx['<PAD>'])\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    # Lists to store losses\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_model = None\n",
    "\n",
    "    # Training loop\n",
    "    print(\"Starting training...\")\n",
    "    pbar = trange(epochs, desc=\"Epoch\", dynamic_ncols=True)\n",
    "    for epoch in pbar:\n",
    "        # Train\n",
    "        train_loss = train(\n",
    "            model=model,\n",
    "            device=device,\n",
    "            dataloader=train_loader,\n",
    "            optimizer=optimizer,\n",
    "            criterion=criterion,\n",
    "            clip=clip,\n",
    "            teacher_forcing_ratio=teacher_forcing_ratio\n",
    "        )\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Validate\n",
    "        val_loss = evaluate(\n",
    "            model=model,\n",
    "            device=device,\n",
    "            dataloader=val_loader,\n",
    "            criterion=criterion\n",
    "        )\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # # Update learning rate based on validation loss\n",
    "        # scheduler.step(val_loss)\n",
    "\n",
    "        # Update tqdm bar description\n",
    "        pbar.set_description(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        pbar.set_postfix(train_loss=f\"{train_loss:.4f}\", val_loss=f\"{val_loss:.4f}\")\n",
    "            \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model = model\n",
    "            torch.save(model.state_dict(), 'best_vanilla_model.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        # Early stopping\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping after {epoch+1} epochs!\")\n",
    "            break\n",
    "    \n",
    "    print(\"best model saved at: best_vanilla_model.pth\")\n",
    "\n",
    "    return train_losses, val_losses, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e4ec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses, best_model = train_model(input_size=input_size, output_size=output_size, train_loader=train_loader, \n",
    "                                       val_loader=val_loader, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d5d824",
   "metadata": {},
   "source": [
    "### Visualize training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be7fe6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53966fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "# plt.savefig('loss_plot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6924fb4",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning with Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26ba7ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c36307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_VAL_LOSS = float('inf')\n",
    "BEST_VAL_ACC = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cba31c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with wandb integration\n",
    "def train_with_wandb(config=None):\n",
    "    global BEST_VAL_LOSS, BEST_VAL_ACC\n",
    "    \n",
    "    # Initialize a new wandb run\n",
    "    with wandb.init(config=config) as run:\n",
    "        # If called by wandb.agent, use the config set by sweep controller\n",
    "        config = wandb.config\n",
    "        \n",
    "        # Generate a descriptive name for the run based on key hyperparameters\n",
    "        run_name = (\n",
    "            f\"ct{config.cell_type}-tfr{config.teacher_forcing_ratio}-lr{config.learning_rate}-es{config.embedding_size}-hs{config.hidden_size}-\"\n",
    "            f\"nl{config.num_layers}-d{config.dropout}-bs{config.batch_size}\"\n",
    "        )\n",
    "        \n",
    "        run.name = run_name\n",
    "        \n",
    "        # Access hyperparameters as wandb.config\n",
    "        config = wandb.config\n",
    "        \n",
    "        # Set seed\n",
    "        set_seed(config.seed)\n",
    "        \n",
    "        # Device\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"Using device: {device}\")\n",
    "        \n",
    "        # Create save directory if it doesn't exist\n",
    "        if not os.path.exists('models'):\n",
    "            os.makedirs('models')\n",
    "        \n",
    "        # Dataset paths\n",
    "        train_path = 'dakshina_dataset_v1.0/ml/lexicons/ml.translit.sampled.train.tsv'\n",
    "        val_path = 'dakshina_dataset_v1.0/ml/lexicons/ml.translit.sampled.dev.tsv'\n",
    "\n",
    "        # Create dataloaders\n",
    "        train_dataset, train_loader = prepare_data(train_path, batch_size=config.batch_size)\n",
    "        val_dataset, val_loader = prepare_data(val_path, batch_size=config.batch_size)\n",
    "\n",
    "        # Make sure val dataset uses the same vocabulary as training\n",
    "        val_dataset.source_char_to_idx = train_dataset.source_char_to_idx\n",
    "        val_dataset.source_idx_to_char = train_dataset.source_idx_to_char\n",
    "        val_dataset.target_char_to_idx = train_dataset.target_char_to_idx\n",
    "        val_dataset.target_idx_to_char = train_dataset.target_idx_to_char\n",
    "        \n",
    "        # Create model\n",
    "        encoder = Encoder(\n",
    "            input_size=train_dataset.get_vocab_size('source'),\n",
    "            embedding_size=config.embedding_size,\n",
    "            hidden_size=config.hidden_size,\n",
    "            n_layers=config.num_layers,\n",
    "            dropout=config.dropout,\n",
    "            cell_type=config.cell_type\n",
    "        )\n",
    "        \n",
    "        decoder = Decoder(\n",
    "            output_size=train_dataset.get_vocab_size('target'),\n",
    "            embedding_size=config.embedding_size,\n",
    "            hidden_size=config.hidden_size,\n",
    "            n_layers=config.num_layers,\n",
    "            dropout=config.dropout,\n",
    "            cell_type=config.cell_type\n",
    "        )\n",
    "        \n",
    "        model = Seq2Seq(encoder, decoder, device).to(device)\n",
    "        \n",
    "        # Optimizer and criterion\n",
    "        optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "        criterion = nn.CrossEntropyLoss(ignore_index=train_dataset.target_char_to_idx['<PAD>'])\n",
    "        \n",
    "        # Train model\n",
    "        best_val_loss = float('inf')\n",
    "        best_val_acc = 0\n",
    "        patience = config.patience\n",
    "        patience_counter = 0\n",
    "\n",
    "        pbar = trange(int(config.epochs), desc=\"Epoch\", dynamic_ncols=True)\n",
    "        for epoch in pbar:\n",
    "            # Train\n",
    "            train_loss = train(\n",
    "                model, device, train_loader, optimizer, criterion, \n",
    "                clip=config.clip, teacher_forcing_ratio=config.teacher_forcing_ratio\n",
    "            )\n",
    "            \n",
    "            # Evaluate\n",
    "            val_loss = evaluate(model, device, val_loader, criterion=criterion)\n",
    "\n",
    "            # Evaluate accuracy on validation set\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch in val_loader:\n",
    "                    source_texts = batch['source_text']\n",
    "                    target_texts = batch['target_text']\n",
    "                    \n",
    "                    for i, source_text in enumerate(source_texts):\n",
    "                        pred_text = transliterate(model, device, val_dataset, source_text)\n",
    "                        \n",
    "                        if pred_text == target_texts[i]:\n",
    "                            correct += 1\n",
    "                        total += 1\n",
    "            \n",
    "            val_acc = correct / total\n",
    "\n",
    "            # Update tqdm bar description\n",
    "            pbar.set_description(f\"Epoch {epoch+1}/{config.epochs}\")\n",
    "            pbar.set_postfix(train_loss=f\"{train_loss:.4f}\", val_loss=f\"{val_loss:.4f}\", val_acc=f\"{val_acc:.4f}\")\n",
    "            \n",
    "            # Log to wandb\n",
    "            wandb.log({\n",
    "                'epoch': epoch + 1,\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss': val_loss,\n",
    "                'val_accuracy':val_acc\n",
    "            })\n",
    "\n",
    "            # Save best model based on validation loss\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_val_acc = val_acc\n",
    "                model_path = os.path.join('models', f'model_{wandb.run.id}.pth')\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "\n",
    "                if best_val_loss < BEST_VAL_LOSS:\n",
    "                    BEST_VAL_LOSS = best_val_loss\n",
    "                    BEST_VAL_ACC = best_val_acc\n",
    "                    torch.save(model.state_dict(), \"best_vanilla_model.pth\")\n",
    "                    \n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            # Early stopping\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping after {epoch+1} epochs!\")\n",
    "                break\n",
    "\n",
    "        # # Load best model for final evaluation\n",
    "        # model.load_state_dict(torch.load(os.path.join('models', f'model_{wandb.run.id}.pth')))\n",
    "        \n",
    "        # # Evaluate accuracy on validation set\n",
    "        # correct = 0\n",
    "        # total = 0\n",
    "        \n",
    "        # with torch.no_grad():\n",
    "        #     for batch in val_loader:\n",
    "        #         source_texts = batch['source_text']\n",
    "        #         target_texts = batch['target_text']\n",
    "                \n",
    "        #         for i, source_text in enumerate(source_texts):\n",
    "        #             pred_text = transliterate(best_model, device, val_dataset, source_text)\n",
    "                    \n",
    "        #             if pred_text == target_texts[i]:\n",
    "        #                 correct += 1\n",
    "        #             total += 1\n",
    "        \n",
    "        # val_accuracy = correct / total\n",
    "        # print(f'Validation Accuracy: {val_accuracy:.3f}')\n",
    "        \n",
    "        # print(f\"\\tBest model saved with val loss {best_val_loss:.3f} at model_{wandb.run.id}.pth\")\n",
    "        print(f\"\\tBest model saved with val acc {best_val_acc:.3f} at model_{wandb.run.id}.pth\")\n",
    "\n",
    "        # Log final metrics\n",
    "        wandb.log({\n",
    "            'best_val_loss': best_val_loss,\n",
    "            'best_val_accuracy': best_val_acc\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e8834fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sweep configuration\n",
    "sweep_config = {\n",
    "    'method': 'bayes',\n",
    "    'name': 'sweep_vanilla',\n",
    "    'metric': {\n",
    "        'name': 'val_loss',\n",
    "        'goal': 'minimize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'seed': {\n",
    "            'value': 42\n",
    "        },\n",
    "        'learning_rate': {\n",
    "           'min': 0.0001, \n",
    "           'max': 0.01\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'values': [32, 64]\n",
    "        },\n",
    "        'embedding_size': {\n",
    "            'values': [64, 128, 256]\n",
    "        },\n",
    "        'hidden_size': {\n",
    "            'values': [128, 256]\n",
    "        },\n",
    "        'num_layers': {\n",
    "            'values': [1, 2]\n",
    "        },\n",
    "        'dropout': {\n",
    "            'values': [0.1, 0.3]\n",
    "        },\n",
    "        'cell_type': {\n",
    "            'values': ['rnn', 'lstm', 'gru']\n",
    "        },\n",
    "        'teacher_forcing_ratio': {\n",
    "            'values': [0.5, 0.7]\n",
    "        },\n",
    "        'clip': {\n",
    "            'value': 1.0\n",
    "        },\n",
    "        'epochs': {\n",
    "            'value': 20\n",
    "        },\n",
    "        'patience': {\n",
    "            'value': 5\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fc2782b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mch21b021\u001b[0m (\u001b[33mch21b021-indian-institute-of-technology-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"vanilla.ipynb\"\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d1b1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: rb9v6cga\n",
      "Sweep URL: https://wandb.ai/ch21b021-indian-institute-of-technology-madras/DA6401-Assignment-3/sweeps/rb9v6cga\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: met6m9h1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.008862437573169575\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tpatience: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tseed: 42\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.5\n",
      "d:\\Anaconda\\Lib\\site-packages\\pydantic\\main.py:308: UserWarning: Pydantic serializer warnings:\n",
      "  Expected `list[str]` but got `tuple` - serialized value may not be as expected\n",
      "  Expected `list[str]` but got `tuple` - serialized value may not be as expected\n",
      "  return self.__pydantic_serializer__.to_python(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Ayaan\\IITM\\Courses\\Sem 8\\DA6401\\DA6401-Assignment-3\\wandb\\run-20250521_153611-met6m9h1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ch21b021-indian-institute-of-technology-madras/DA6401-Assignment-3/runs/met6m9h1' target=\"_blank\">peach-sweep-1</a></strong> to <a href='https://wandb.ai/ch21b021-indian-institute-of-technology-madras/DA6401-Assignment-3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ch21b021-indian-institute-of-technology-madras/DA6401-Assignment-3/sweeps/rb9v6cga' target=\"_blank\">https://wandb.ai/ch21b021-indian-institute-of-technology-madras/DA6401-Assignment-3/sweeps/rb9v6cga</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ch21b021-indian-institute-of-technology-madras/DA6401-Assignment-3' target=\"_blank\">https://wandb.ai/ch21b021-indian-institute-of-technology-madras/DA6401-Assignment-3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/ch21b021-indian-institute-of-technology-madras/DA6401-Assignment-3/sweeps/rb9v6cga' target=\"_blank\">https://wandb.ai/ch21b021-indian-institute-of-technology-madras/DA6401-Assignment-3/sweeps/rb9v6cga</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ch21b021-indian-institute-of-technology-madras/DA6401-Assignment-3/runs/met6m9h1' target=\"_blank\">https://wandb.ai/ch21b021-indian-institute-of-technology-madras/DA6401-Assignment-3/runs/met6m9h1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20:  50%|█████     | 10/20 [22:20<22:09, 132.93s/it, train_loss=0.7445, val_acc=0.2239, val_loss=1.4353]"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project='DA6401-Assignment-3')\n",
    "\n",
    "# Run the sweep\n",
    "wandb.agent(sweep_id, train_with_wandb, count=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28e47cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_errors(predictions):\n",
    "    \"\"\"\n",
    "    Analyze the errors made by the model\n",
    "    \"\"\"\n",
    "    # Count total predictions and correct predictions\n",
    "    total = len(predictions)\n",
    "    correct = sum(1 for _, pred, target in predictions if pred == target)\n",
    "    \n",
    "    print(f'Accuracy: {correct/total:.3f} ({correct}/{total})')\n",
    "    \n",
    "    # Analyze error patterns\n",
    "    errors = [(source, pred, target) for source, pred, target in predictions if pred != target]\n",
    "    \n",
    "    # Error by length\n",
    "    length_errors = {}\n",
    "    for source, _, target in errors:\n",
    "        length = len(source)\n",
    "        if length not in length_errors:\n",
    "            length_errors[length] = 0\n",
    "        length_errors[length] += 1\n",
    "    \n",
    "    # Sort by length\n",
    "    sorted_length_errors = {k: v for k, v in sorted(length_errors.items())}\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(sorted_length_errors.keys(), sorted_length_errors.values())\n",
    "    plt.xlabel('Source Length')\n",
    "    plt.ylabel('Number of Errors')\n",
    "    plt.title('Errors by Source Length')\n",
    "    plt.savefig('predictions_vanilla/errors_by_length.png')\n",
    "    \n",
    "    # Sample error analysis\n",
    "    print(\"\\nSample Error Analysis:\")\n",
    "    for i, (source, pred, target) in enumerate(errors[:10]):\n",
    "        print(f'Source: {source}')\n",
    "        print(f'Prediction: {pred}')\n",
    "        print(f'Target: {target}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "85e2f6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_best_model(best_config, model_path):\n",
    "    # Load datasets\n",
    "    train_dataset_path = \"dakshina_dataset_v1.0/ml/lexicons/ml.translit.sampled.train.tsv\"\n",
    "    test_dataset_path = \"dakshina_dataset_v1.0/ml/lexicons/ml.translit.sampled.test.tsv\"\n",
    "    \n",
    "    train_dataset, _ = prepare_data(train_dataset_path, batch_size=best_config['batch_size'], shuffle=False)\n",
    "    test_dataset, test_dataloader = prepare_data(test_dataset_path, batch_size=best_config['batch_size'], shuffle=False)\n",
    "    \n",
    "    # Make sure test dataset uses the same vocabulary as training\n",
    "    test_dataset.source_char_to_idx = train_dataset.source_char_to_idx\n",
    "    test_dataset.source_idx_to_char = train_dataset.source_idx_to_char\n",
    "    test_dataset.target_char_to_idx = train_dataset.target_char_to_idx\n",
    "    test_dataset.target_idx_to_char = train_dataset.target_idx_to_char\n",
    "\n",
    "    # Initialize model with best configuration\n",
    "    input_size = train_dataset.get_vocab_size('source')\n",
    "    output_size = train_dataset.get_vocab_size('target')\n",
    "        \n",
    "    # Device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")    \n",
    "\n",
    "    best_encoder = Encoder(\n",
    "        input_size=input_size, \n",
    "        embedding_size=best_config['embedding_size'], \n",
    "        hidden_size=best_config['hidden_size'], \n",
    "        n_layers=best_config['num_layers'], \n",
    "        dropout=best_config['dropout'],\n",
    "        cell_type=best_config['cell_type']\n",
    "    )\n",
    "    \n",
    "    best_decoder = Decoder(\n",
    "        output_size=output_size, \n",
    "        embedding_size=best_config['embedding_size'], \n",
    "        hidden_size=best_config['hidden_size'], \n",
    "        n_layers=best_config['num_layers'], \n",
    "        dropout=best_config['dropout'],\n",
    "        cell_type=best_config['cell_type']\n",
    "    )\n",
    "    \n",
    "    best_model = Seq2Seq(best_encoder, best_decoder, device).to(device)\n",
    "    \n",
    "    # Load model parameters\n",
    "    best_model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_accuracy, test_predictions = calculate_accuracy(best_model, device, test_dataloader, train_dataset)\n",
    "    \n",
    "    print(f'Test Accuracy: {test_accuracy:.3f}')\n",
    "    \n",
    "    # Save predictions to file\n",
    "    with open('predictions_vanilla/test_predictions.txt', 'w', encoding='utf-8') as f:\n",
    "        for source, pred, target in test_predictions:\n",
    "            f.write(f'Source: {source}\\n')\n",
    "            f.write(f'Prediction: {pred}\\n')\n",
    "            f.write(f'Target: {target}\\n\\n')\n",
    "    \n",
    "    # Create error analysis\n",
    "    analyze_errors(test_predictions)\n",
    "    \n",
    "    return test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d298f16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_config = {'embedding_size': 256, 'hidden_size': 128, 'num_layers': 2, 'dropout': 0.1, 'cell_type': 'rnn', 'batch_size': 64}\n",
    "\n",
    "best_model_path = \"models/model_0bp4kcni.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "27edbd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure predictions directory exists\n",
    "os.makedirs('predictions_vanilla', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7fbacaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Test Accuracy: 0.000\n",
      "Accuracy: 0.000 (0/5610)\n",
      "\n",
      "Sample Error Analysis:\n",
      "Source: adisthaanamaakkiyaanu\n",
      "Prediction: സ്ക്\n",
      "Target: അടിസ്ഥാനമാക്കിയാണ്\n",
      "\n",
      "Source: atisthaanamaakkiyaanu\n",
      "Prediction: സ്ക്\n",
      "Target: അടിസ്ഥാനമാക്കിയാണ്\n",
      "\n",
      "Source: adisthaanamaakkiya\n",
      "Prediction: സ്ക്\n",
      "Target: അടിസ്ഥാനമാക്കിയ\n",
      "\n",
      "Source: atisthaanamaakkiya\n",
      "Prediction: സ്ക്\n",
      "Target: അടിസ്ഥാനമാക്കിയ\n",
      "\n",
      "Source: adangunnathaanu\n",
      "Prediction: സ്ക്\n",
      "Target: അടങ്ങുന്നതാണ്\n",
      "\n",
      "Source: amgeekarikkuka\n",
      "Prediction: സ്ക്\n",
      "Target: അംഗീകരിക്കുക\n",
      "\n",
      "Source: angeekarikkuka\n",
      "Prediction: സ്ക്\n",
      "Target: അംഗീകരിക്കുക\n",
      "\n",
      "Source: adangunnathaan\n",
      "Prediction: സ്ക്\n",
      "Target: അടങ്ങുന്നതാണ്\n",
      "\n",
      "Source: atangunnathaan\n",
      "Prediction: സ്ക്\n",
      "Target: അടങ്ങുന്നതാണ്\n",
      "\n",
      "Source: adayaalamaayi\n",
      "Prediction: സ്ക്\n",
      "Target: അടയാളമായി\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1IAAAIhCAYAAABE54vcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABCXklEQVR4nO3de3RNd/7/8deRu4iQIEcqIlXqEurWurTELVSDGu2XVluUtjouFZfxk2pJO22UTlVF6U0lGDXftph2TBFFOujFZVLXUdeKSqQVTVwyCbJ/f/TrrB4J8iFxTng+1tprdX/2Z+/93sdeh1c/e3+OzbIsSwAAAACAEqvg6gIAAAAAoLwhSAEAAACAIYIUAAAAABgiSAEAAACAIYIUAAAAABgiSAEAAACAIYIUAAAAABgiSAEAAACAIYIUAAAAABgiSAGAiyUlJclms112Wb9+vatLvGZ16tRRz549y/w8J06cUFxcnBo1aiR/f38FBgaqQYMGeuKJJ7R9+/YyP7+rDB48WJUqVXJ1GZe1adMmxcfH69dffy2y7UbdGwBQVjxdXQAA4Dfz589XgwYNirQ3atTIBdWUH6dPn1abNm10+vRp/elPf9Jdd92lvLw8/fDDD1q6dKnS0tLUtGlTV5d5S9q0aZNeeuklDR48WFWqVHF1OQBQqghSAOAmIiMj1apVK6N9LMvSf//7X/n5+RXZlpeXJ19fX9lstmuu6ezZs6pYseI1738jfPzxx9q/f7/Wrl2rTp06OW0bO3asCgsLb3hNeXl5xf6ZAABuHjzaBwDliM1m08iRI/XOO++oYcOG8vHxUXJysuPxwNWrV2vIkCGqXr26KlasqPz8fBUWFmr69Olq0KCBfHx8VKNGDQ0cOFBHjx51OnbHjh0VGRmpr776Su3atVPFihU1ZMgQSdLatWvVsWNHBQcHy8/PT7Vr19ZDDz2ks2fPlqjuZcuWqWnTpvL19dXtt9+uWbNmObadPn1aVapU0bBhw4rsd/jwYXl4eOj111+/7LFPnDghSapZs2ax2ytUcP6rbsOGDerSpYsCAgJUsWJFtWvXTitWrHDqEx8fX2wAvfg5Hz582NF28RG1pUuXqnnz5vL19dVLL70kSfrpp5/0zDPPKCwsTN7e3goNDdXDDz+s48ePO/bPzc3V+PHjFRERIW9vb912222KjY3VmTNnLnvNptasWaMuXbqocuXKqlixou699159+eWXxV7zrl279OijjyowMFAhISEaMmSIcnJynPr++uuvGjp0qIKCglSpUiXFxMTo4MGDstlsio+PdxzvT3/6kyQpIiLiso+qrly5Ui1atJCfn58aNGigDz/8sNSuGwDKEiNSAOAmLly4oPPnzzu12Ww2eXh4OLUtX75c//rXvzR58mTZ7XbVqFFDmzdvliQNGTJEMTExWrhwoc6cOSMvLy/98Y9/1HvvvaeRI0eqZ8+eOnz4sF588UWtX79e27ZtU7Vq1RzHzsjI0OOPP64JEyYoISFBFSpU0OHDhxUTE6P27dvrww8/VJUqVfTTTz9p5cqVKigouOqIVVpammJjYxUfHy+73a6//vWvGj16tAoKCjR+/HhVqlRJQ4YM0Xvvvafp06crMDDQse+cOXPk7e3tCHTFadu2rSRp4MCBev7559W+fXsFBwcX2zc1NVXR0dFq2rSp5s2bJx8fH82ZM0e9evXSRx99pP79+1/xWi5n27Zt2rNnj1544QVFRETI399fP/30k+6++26dO3dOzz//vJo2baoTJ05o1apVOnnypEJCQnT27FlFRUXp6NGjjj67du3S5MmTtWPHDq1Zs+a6RhQladGiRRo4cKAefPBBJScny8vLS++++666d++uVatWqUuXLk79H3roIfXv319Dhw7Vjh07FBcXJ0mOgFNYWKhevXppy5Ytio+PV4sWLfT111/r/vvvdzrOU089pezsbCUmJmrp0qWOoPv7R1W///57jRs3ThMnTlRISIg++OADDR06VHfccYc6dOhwXdcNAGXOAgC41Pz58y1JxS4eHh5OfSVZgYGBVnZ2drHHGDhwoFP7nj17LEnW8OHDndq//fZbS5L1/PPPO9qioqIsSdaXX37p1PeTTz6xJFlpaWnG1xYeHm7ZbLYi+0ZHR1uVK1e2zpw5Y1mWZR04cMCqUKGC9eabbzr65OXlWcHBwdaTTz551fO8/PLLlre3t+Nzi4iIsJ599lnr+++/d+rXpk0bq0aNGtapU6ccbefPn7ciIyOtWrVqWYWFhZZlWdaUKVOs4v6KvPg5Hzp0yOkaPTw8rL179zr1HTJkiOXl5WXt3r37snVPnTrVqlChgrV582an9ouf+T//+c8rXvegQYMsf3//y24/c+aMFRQUZPXq1cup/cKFC9Zdd91l3XPPPY62i9c8ffp0p77Dhw+3fH19HZ/NihUrLEnW3Llzi1yLJGvKlCmOttdff73I53VReHi45evra/3444+Otry8PCsoKMgaNmzYFa8bANwBj/YBgJtYsGCBNm/e7LR8++23Rfp17txZVatWLfYYDz30kNP6unXrJP02u9vv3XPPPWrYsGGRx7uqVq2qzp07O7U1a9ZM3t7eeuaZZ5ScnKyDBw8aXVfjxo111113ObUNGDBAubm52rZtmyTp9ttvV8+ePTVnzhxZliVJWrx4sU6cOKGRI0de9Rwvvviijhw5og8//FDDhg1TpUqV9M4776hly5b66KOPJElnzpzRt99+q4cffthppjsPDw898cQTOnr0qPbu3Wt0bRc1bdpU9evXd2r74osv1KlTJzVs2PCy+/3jH/9QZGSkmjVrpvPnzzuW7t27l8qMjZs2bVJ2drYGDRrkdPzCwkLdf//92rx5c5FHCHv37l3k2v773/8qKytL0m+jepLUr18/p36PPvqocX3NmjVT7dq1Heu+vr6qX7++fvzxR+NjAcCNRpACADfRsGFDtWrVymlp2bJlkX6XexeouG1Xen8oNDTUsf1Kx65bt67WrFmjGjVqaMSIEapbt67q1q2rt956q0TXZbfbL9v2+/OPHj1a+/btU0pKiiTp7bffVtu2bdWiRYsSnSckJERPPvmk3nnnHW3fvl2pqany9vbW6NGjJUknT56UZVmX/SwurcdEccf8+eefVatWrSvud/z4cW3fvl1eXl5OS0BAgCzL0i+//HJN9fz++JL08MMPFznHtGnTZFmWsrOznfa59LFIHx8fSb9NoCH99hl5enoqKCjIqV9ISIhxfcU9gunj4+M4FwC4M96RAoBy5krvzFy67eI/VDMyMor8o/7YsWNO70dd6djt27dX+/btdeHCBW3ZskWJiYmKjY1VSEiIHnnkkSvWm5mZedm23/9DunPnzoqMjNTs2bNVqVIlbdu2TYsWLbrisa+kQ4cO6tatm5YvX66srCxVrVpVFSpUUEZGRpG+x44dkyTH5+Hr6ytJys/PdwQJSZcNNsV9btWrVy8yocelqlWrJj8/v8tOsHDpn4+pi/snJiaqTZs2xfYxDUDBwcE6f/68srOzncJUcX/OAHAzY0QKAG5iFx/TuzSQbN68WXv27Cky0cDVeHh4qHXr1nr77bclyfFo3pXs2rVL33//vVPb4sWLFRAQUGS06bnnntOKFSsUFxenkJAQ/c///M9Vj3/8+PFipzi/cOGC9u3bp4oVK6pKlSry9/dX69attXTpUqcRj8LCQi1atEi1atVyPJ5Xp04dSSryY76ff/75Veu5qEePHlq3bt0VHxfs2bOnDhw4oODg4CKjka1atXLUca3uvfdeValSRbt37y72+K1atZK3t7fRMaOioiRJf/vb35zalyxZUqTvpaNZAHAzYUQKANzEzp07i8zaJ/32aF316tWv6Zh33nmnnnnmGSUmJqpChQrq0aOHY9a+sLAwjRkz5qrHeOedd7R27VrFxMSodu3a+u9//+sYQenatetV9w8NDVXv3r0VHx+vmjVratGiRUpJSdG0adOKzPj3+OOPKy4uTl999ZVeeOGFEv0jf+HChXr33Xc1YMAA3X333QoMDNTRo0f1wQcfOGbAu3icqVOnKjo6Wp06ddL48ePl7e2tOXPmaOfOnfroo48cI0sPPPCAgoKCNHToUL388svy9PRUUlKS0tPTr1rPRS+//LK++OILdejQQc8//7yaNGmiX3/9VStXrtTYsWPVoEEDxcbG6tNPP1WHDh00ZswYNW3aVIWFhTpy5IhWr16tcePGqXXr1lc8z4ULF/TJJ58Uaff391ePHj2UmJioQYMGKTs7Ww8//LBq1Kihn3/+Wd9//71+/vlnzZ07t8TXJEn333+/7r33Xo0bN065ublq2bKlvv76ay1YsECS83TzTZo0kSS99dZbGjRokLy8vHTnnXcqICDA6JwA4JZcO9cFAOBKs/ZJst5//31HX0nWiBEjLnuMS2d/s6zfZmibNm2aVb9+fcvLy8uqVq2a9fjjj1vp6elO/aKioqzGjRsX2f/rr7+2/vCHP1jh4eGWj4+PFRwcbEVFRVmfffbZVa8tPDzciomJsT755BOrcePGlre3t1WnTh1rxowZl91n8ODBlqenp3X06NGrHt+yLGv37t3WuHHjrFatWlnVq1e3PD09rapVq1pRUVHWwoULi/T/17/+ZXXu3Nny9/e3/Pz8rDZt2liff/55kX7fffed1a5dO8vf39+67bbbrClTplgffPBBsbP2xcTEFFtbenq6NWTIEMtut1teXl5WaGio1a9fP+v48eOOPqdPn7ZeeOEF684777S8vb2twMBAq0mTJtaYMWOszMzMK177oEGDLnvfhIeHO/qlpqZaMTExVlBQkOXl5WXddtttVkxMjPXxxx87+lycte/nn392OkdxMxVmZ2dbTz75pFWlShWrYsWKVnR0tPXNN99Ykqy33nrLaf+4uDgrNDTUqlChgiXJWrdu3RU/t6ioKCsqKuqK1w0A7sBmWf83PRIAAC5WUFCgOnXq6L777tP//u//urocGFi8eLEee+wxbdy4Ue3atXN1OQBQ5ni0DwDgcj///LP27t2r+fPn6/jx45o4caKrS8IVfPTRR/rpp5/UpEkTVahQQd98841ef/11dejQgRAF4JZBkAIAuNyKFSv05JNPqmbNmpozZ06JpzyHawQEBGjJkiV65ZVXdObMGdWsWVODBw/WK6+84urSAOCG4dE+AAAAADDE9OcAAAAAYIggBQAAAACGCFIAAAAAYIjJJvTbr9ofO3ZMAQEBjh9jBAAAAHDrsSxLp06dUmhoqNOPjF+KICXp2LFjCgsLc3UZAAAAANxEenq6atWqddntBCn9No2r9NuHVblyZRdXAwAAAMBVcnNzFRYW5sgIl0OQkhyP81WuXJkgBQAAAOCqr/ww2QQAAAAAGCJIAQAAAIAhghQAAAAAGCJIAQAAAIAhghQAAAAAGCJIAQAAAIAhghQAAAAAGCJIAQAAAIAhghQAAAAAGCJIAQAAAIAhghQAAAAAGCJIAQAAAIAhghQAAAAAGCJIAQAAAIAhghQAAAAAGCJIAQAAAIAhghQAAAAAGCJIAQAAAIAhghQAAAAAGPJ0dQEAbk11Jq4o0+Mffi2mTI8PAABubYxIAQAAAIAhghQAAAAAGCJIAQAAAIAhghQAAAAAGCJIAQAAAIAhghQAAAAAGCJIAQAAAIAhghQAAAAAGCJIAQAAAIAhghQAAAAAGCJIAQAAAIAhghQAAAAAGCJIAQAAAIAhghQAAAAAGCJIAQAAAIAhghQAAAAAGCJIAQAAAIAhghQAAAAAGCJIAQAAAIAhghQAAAAAGCJIAQAAAIAhghQAAAAAGCJIAQAAAIAhT1cXAMB16kxcUabHP/xaTJkeHwAAwFUYkQIAAAAAQwQpAAAAADBEkAIAAAAAQwQpAAAAADBEkAIAAAAAQwQpAAAAADBEkAIAAAAAQwQpAAAAADDED/ICwA1S1j+ALPEjyAAA3CiMSAEAAACAIYIUAAAAABgiSAEAAACAIYIUAAAAABgiSAEAAACAIYIUAAAAABgiSAEAAACAIYIUAAAAABhyaZCKj4+XzWZzWux2u2O7ZVmKj49XaGio/Pz81LFjR+3atcvpGPn5+Ro1apSqVasmf39/9e7dW0ePHr3RlwIAAADgFuLyEanGjRsrIyPDsezYscOxbfr06ZoxY4Zmz56tzZs3y263Kzo6WqdOnXL0iY2N1bJly7RkyRJt2LBBp0+fVs+ePXXhwgVXXA4AAACAW4Cnywvw9HQahbrIsizNnDlTkyZNUt++fSVJycnJCgkJ0eLFizVs2DDl5ORo3rx5Wrhwobp27SpJWrRokcLCwrRmzRp179692HPm5+crPz/fsZ6bm1sGVwYAAADgZuXyEal9+/YpNDRUEREReuSRR3Tw4EFJ0qFDh5SZmalu3bo5+vr4+CgqKkqbNm2SJG3dulXnzp1z6hMaGqrIyEhHn+JMnTpVgYGBjiUsLKyMrg4AAADAzcilQap169ZasGCBVq1apffff1+ZmZlq166dTpw4oczMTElSSEiI0z4hISGObZmZmfL29lbVqlUv26c4cXFxysnJcSzp6emlfGUAAAAAbmYufbSvR48ejv9u0qSJ2rZtq7p16yo5OVlt2rSRJNlsNqd9LMsq0napq/Xx8fGRj4/PdVQOAAAA4Fbm8kf7fs/f319NmjTRvn37HO9NXTqylJWV5RilstvtKigo0MmTJy/bBwAAAABKm8snm/i9/Px87dmzR+3bt1dERITsdrtSUlLUvHlzSVJBQYFSU1M1bdo0SVLLli3l5eWllJQU9evXT5KUkZGhnTt3avr06S67DsBEnYkryvT4h1+LKdPjAwAA3IpcGqTGjx+vXr16qXbt2srKytIrr7yi3NxcDRo0SDabTbGxsUpISFC9evVUr149JSQkqGLFihowYIAkKTAwUEOHDtW4ceMUHBysoKAgjR8/Xk2aNHHM4gcAAAAApc2lQero0aN69NFH9csvv6h69epq06aNvvnmG4WHh0uSJkyYoLy8PA0fPlwnT55U69attXr1agUEBDiO8eabb8rT01P9+vVTXl6eunTpoqSkJHl4eLjqsgC4sbIeAZQYBQQA4Fbg0iC1ZMmSK2632WyKj49XfHz8Zfv4+voqMTFRiYmJpVwdAAAAABTPrSabAAAAAIDygCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgyKW/IwUAuDH4IWIAAEoXI1IAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYMjT1QUAAFBW6kxcUebnOPxaTJmfAwDgfhiRAgAAAABDjEgBAMoUo0IAgJsRQQoQ/9ADAACAGR7tAwAAAABDBCkAAAAAMESQAgAAAABDBCkAAAAAMESQAgAAAABDBCkAAAAAMESQAgAAAABDBCkAAAAAMOQ2QWrq1Kmy2WyKjY11tFmWpfj4eIWGhsrPz08dO3bUrl27nPbLz8/XqFGjVK1aNfn7+6t37946evToDa4eAAAAwK3ELYLU5s2b9d5776lp06ZO7dOnT9eMGTM0e/Zsbd68WXa7XdHR0Tp16pSjT2xsrJYtW6YlS5Zow4YNOn36tHr27KkLFy7c6MsAAAAAcItweZA6ffq0HnvsMb3//vuqWrWqo92yLM2cOVOTJk1S3759FRkZqeTkZJ09e1aLFy+WJOXk5GjevHl644031LVrVzVv3lyLFi3Sjh07tGbNGlddEgAAAICbnMuD1IgRIxQTE6OuXbs6tR86dEiZmZnq1q2bo83Hx0dRUVHatGmTJGnr1q06d+6cU5/Q0FBFRkY6+hQnPz9fubm5TgsAAAAAlJSnK0++ZMkSbdu2TZs3by6yLTMzU5IUEhLi1B4SEqIff/zR0cfb29tpJOtin4v7F2fq1Kl66aWXrrd8AAAAALcol41Ipaena/To0Vq0aJF8fX0v289mszmtW5ZVpO1SV+sTFxennJwcx5Kenm5WPAAAAIBbmsuC1NatW5WVlaWWLVvK09NTnp6eSk1N1axZs+Tp6ekYibp0ZCkrK8uxzW63q6CgQCdPnrxsn+L4+PiocuXKTgsAAAAAlJTLglSXLl20Y8cOpaWlOZZWrVrpscceU1pamm6//XbZ7XalpKQ49ikoKFBqaqratWsnSWrZsqW8vLyc+mRkZGjnzp2OPgAAAABQ2lz2jlRAQIAiIyOd2vz9/RUcHOxoj42NVUJCgurVq6d69eopISFBFStW1IABAyRJgYGBGjp0qMaNG6fg4GAFBQVp/PjxatKkSZHJKwAAAACgtLh0somrmTBhgvLy8jR8+HCdPHlSrVu31urVqxUQEODo8+abb8rT01P9+vVTXl6eunTpoqSkJHl4eLiwcgAAAAA3M7cKUuvXr3dat9lsio+PV3x8/GX38fX1VWJiohITE8u2OAAAAAD4Py7/HSkAAAAAKG8IUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgyDhI5eXl6ezZs471H3/8UTNnztTq1atLtTAAAAAAcFfGQerBBx/UggULJEm//vqrWrdurTfeeEMPPvig5s6dW+oFAgAAAIC7MQ5S27ZtU/v27SVJn3zyiUJCQvTjjz9qwYIFmjVrVqkXCAAAAADuxjhInT17VgEBAZKk1atXq2/fvqpQoYLatGmjH3/8sdQLBAAAAAB3Yxyk7rjjDi1fvlzp6elatWqVunXrJknKyspS5cqVS71AAAAAAHA3xkFq8uTJGj9+vOrUqaPWrVurbdu2kn4bnWrevHmpFwgAAAAA7sbTdIeHH35Y9913nzIyMnTXXXc52rt06aI//OEPpVocAAAAALgjoyB1/vx5+fr6Ki0trcjo0z333FOqhQEAAACAuzJ6tM/T01Ph4eG6cOFCWdUDAAAAAG7P+B2pF154QXFxccrOzi6LegAAAADA7Rm/IzVr1izt379foaGhCg8Pl7+/v9P2bdu2lVpxAAAAAOCOjINUnz59yqAMAAAAACg/jIPUlClTyqIOAAAAACg3jIPURVu3btWePXtks9nUqFEjfkMKAAAAwC3DOEhlZWXpkUce0fr161WlShVZlqWcnBx16tRJS5YsUfXq1cuiTgAAAABwG8az9o0aNUq5ubnatWuXsrOzdfLkSe3cuVO5ubl67rnnyqJGAAAAAHArxiNSK1eu1Jo1a9SwYUNHW6NGjfT222+rW7dupVocAAAAALgj4xGpwsJCeXl5FWn38vJSYWFhqRQFAAAAAO7MOEh17txZo0eP1rFjxxxtP/30k8aMGaMuXbqUanEAAAAA4I6Mg9Ts2bN16tQp1alTR3Xr1tUdd9yhiIgInTp1SomJiWVRIwAAAAC4FeN3pMLCwrRt2zalpKToP//5jyzLUqNGjdS1a9eyqA8AAAAA3I5RkDp//rx8fX2Vlpam6OhoRUdHl1VdAAAAAOC2jB7t8/T0VHh4uC5cuFBW9QAAAACA2zN+R+qFF15QXFycsrOzy6IeAAAAAHB7xu9IzZo1S/v371doaKjCw8Pl7+/vtH3btm2lVhwAAAAAuCPjINWnT58yKAMAAAAAyg/jySYkaciQIQoLCyuTggAAAADA3RlPNvGXv/yFySYAAAAA3NKMJ5vo0qWL1q9fXwalAAAAAED5YPyOVI8ePRQXF6edO3eqZcuWRSab6N27d6kVBwAAAADuyDhI/fGPf5QkzZgxo8g2m83GY38AAAAAbnrGQaqwsLAs6gAAAACAcsP4HSkAAAAAuNWVOEg98MADysnJcay/+uqr+vXXXx3rJ06cUKNGjUq1OAAAAABwRyUOUqtWrVJ+fr5jfdq0acrOznasnz9/Xnv37i3d6gAAAADADZU4SFmWdcV1AAAAALhV8I4UAAAAABgqcZCy2Wyy2WxF2gAAAADgVlPi6c8ty9LgwYPl4+MjSfrvf/+rZ5991vGDvL9/fwoAAAAAbmYlDlKDBg1yWn/88ceL9Bk4cOD1VwQAAAAAbq7EQWr+/PllWQcAAAAAlBtMNgEAAAAAhghSAAAAAGCIIAUAAAAAhghSAAAAAGCoREGqRYsWOnnypCTp5Zdf1tmzZ8u0KAAAAABwZyUKUnv27NGZM2ckSS+99JJOnz5dpkUBAAAAgDsr0fTnzZo105NPPqn77rtPlmXpL3/5iypVqlRs38mTJ5dqgQAAAADgbko0IpWUlKTg4GD94x//kM1m0xdffKFly5YVWZYvX2508rlz56pp06aqXLmyKleurLZt2+qLL75wbLcsS/Hx8QoNDZWfn586duyoXbt2OR0jPz9fo0aNUrVq1eTv76/evXvr6NGjRnUAAAAAgIkSjUjdeeedWrJkiSSpQoUK+vLLL1WjRo3rPnmtWrX02muv6Y477pAkJScn68EHH9S///1vNW7cWNOnT9eMGTOUlJSk+vXr65VXXlF0dLT27t2rgIAASVJsbKw+//xzLVmyRMHBwRo3bpx69uyprVu3ysPD47prBAAAAIBLGc/aV1hYWCohSpJ69eqlBx54QPXr11f9+vX16quvqlKlSvrmm29kWZZmzpypSZMmqW/fvoqMjFRycrLOnj2rxYsXS5JycnI0b948vfHGG+ratauaN2+uRYsWaceOHVqzZk2p1AgAAAAAl7qm6c8PHDigUaNGqWvXroqOjtZzzz2nAwcOXFchFy5c0JIlS3TmzBm1bdtWhw4dUmZmprp16+bo4+Pjo6ioKG3atEmStHXrVp07d86pT2hoqCIjIx19ipOfn6/c3FynBQAAAABKyjhIrVq1So0aNdJ3332npk2bKjIyUt9++60aN26slJQU4wJ27NihSpUqycfHR88++6yWLVumRo0aKTMzU5IUEhLi1D8kJMSxLTMzU97e3qpatepl+xRn6tSpCgwMdCxhYWHGdQMAAAC4dZXoHanfmzhxosaMGaPXXnutSPv/+3//T9HR0UbHu/POO5WWlqZff/1Vn376qQYNGqTU1FTHdpvN5tTfsqwibZe6Wp+4uDiNHTvWsZ6bm0uYAgAAAFBixiNSe/bs0dChQ4u0DxkyRLt37zYuwNvbW3fccYdatWqlqVOn6q677tJbb70lu90uSUVGlrKyshyjVHa7XQUFBY4fCy6uT3F8fHwcMwVeXAAAAACgpIyDVPXq1ZWWllakPS0trVQmobAsS/n5+YqIiJDdbnd6XLCgoECpqalq166dJKlly5by8vJy6pORkaGdO3c6+gAAAABAaTN+tO/pp5/WM888o4MHD6pdu3ay2WzasGGDpk2bpnHjxhkd6/nnn1ePHj0UFhamU6dOacmSJVq/fr1Wrlwpm82m2NhYJSQkqF69eqpXr54SEhJUsWJFDRgwQJIUGBiooUOHaty4cQoODlZQUJDGjx+vJk2aqGvXrqaXBgAAAAAlYhykXnzxRQUEBOiNN95QXFycpN9myouPj9dzzz1ndKzjx4/riSeeUEZGhgIDA9W0aVOtXLnS8Z7VhAkTlJeXp+HDh+vkyZNq3bq1Vq9e7fgNKUl688035enpqX79+ikvL09dunRRUlISvyEFAAAAoMwYBymbzaYxY8ZozJgxOnXqlCQ5BRsT8+bNu+q54uPjFR8ff9k+vr6+SkxMVGJi4jXVAAAAAACmjIPU711rgAIAAACA8uyafpAXAAAAAG5lBCkAAAAAMESQAgAAAABDRkHq3Llz6tSpk3744YeyqgcAAAAA3J5RkPLy8tLOnTtls9nKqh4AAAAAcHvGj/YNHDjwqtOWAwAAAMDNzHj684KCAn3wwQdKSUlRq1at5O/v77R9xowZpVYcAADlVZ2JK8r8HIdfiynzcwAAimccpHbu3KkWLVpIUpF3pXjkDwAAAMCtwDhIrVu3rizqAAAAAIBy45qnP9+/f79WrVqlvLw8SZJlWaVWFAAAAAC4M+MgdeLECXXp0kX169fXAw88oIyMDEnSU089pXHjxpV6gQAAAADgboyD1JgxY+Tl5aUjR46oYsWKjvb+/ftr5cqVpVocAAAAALgj43ekVq9erVWrVqlWrVpO7fXq1dOPP/5YaoUBAAAAgLsyHpE6c+aM00jURb/88ot8fHxKpSgAAAAAcGfGQapDhw5asGCBY91ms6mwsFCvv/66OnXqVKrFAQAAAIA7Mn607/XXX1fHjh21ZcsWFRQUaMKECdq1a5eys7O1cePGsqgRAAAAANyK8YhUo0aNtH37dt1zzz2Kjo7WmTNn1LdvX/373/9W3bp1y6JGAAAAAHArxiNSkmS32/XSSy+Vdi0AAAAAUC5cU5A6efKk5s2bpz179shms6lhw4Z68sknFRQUVNr1AQAAAIDbMX60LzU1VREREZo1a5ZOnjyp7OxszZo1SxEREUpNTS2LGgEAAADArRiPSI0YMUL9+vXT3Llz5eHhIUm6cOGChg8frhEjRmjnzp2lXiQAAAAAuBPjEakDBw5o3LhxjhAlSR4eHho7dqwOHDhQqsUBAAAAgDsyDlItWrTQnj17irTv2bNHzZo1K42aAAAAAMCtlejRvu3btzv++7nnntPo0aO1f/9+tWnTRpL0zTff6O2339Zrr71WNlUCAAAAgBspUZBq1qyZbDabLMtytE2YMKFIvwEDBqh///6lVx0AAAAAuKESBalDhw6VdR0AAAAAUG6UKEiFh4eXdR0AAAAAUG5c0w/y/vTTT9q4caOysrJUWFjotO25554rlcIAAAAAwF0ZB6n58+fr2Weflbe3t4KDg2Wz2RzbbDYbQQoAAADATc84SE2ePFmTJ09WXFycKlQwnj0dAAAAAMo94yR09uxZPfLII4QoAAAAALcs4zQ0dOhQffzxx2VRCwAAAACUC8aP9k2dOlU9e/bUypUr1aRJE3l5eTltnzFjRqkVBwAAAADuyDhIJSQkaNWqVbrzzjslqchkEwAAAABwszMOUjNmzNCHH36owYMHl0E5AAAAAOD+jN+R8vHx0b333lsWtQAAAABAuWAcpEaPHq3ExMSyqAUAAAAAygXjR/u+++47rV27Vv/4xz/UuHHjIpNNLF26tNSKAwAAAAB3ZBykqlSpor59+5ZFLQAAAABQLhgHqfnz55dFHQAAAABQbhgHKQAA4N7qTFxR5uc4/FpMmZ8DANyZcZCKiIi44u9FHTx48LoKAgAAAAB3ZxykYmNjndbPnTunf//731q5cqX+9Kc/lVZdAAAAAOC2jIPU6NGji21/++23tWXLlusuCAAAAADcnfHvSF1Ojx499Omnn5bW4QAAAADAbZVakPrkk08UFBRUWocDAAAAALdl/Ghf8+bNnSabsCxLmZmZ+vnnnzVnzpxSLQ4AAAAA3JFxkOrTp4/TeoUKFVS9enV17NhRDRo0KK26AAAAAMBtGQepKVOmlEUdAAAAAFBulNo7UgAAAABwqyjxiFSFChWu+EO8kmSz2XT+/PnrLgoAAAAA3FmJg9SyZcsuu23Tpk1KTEyUZVmlUhQAAAAAuLMSB6kHH3ywSNt//vMfxcXF6fPPP9djjz2mP//5z6VaHAAAAAC4o2t6R+rYsWN6+umn1bRpU50/f15paWlKTk5W7dq1S7s+AAAAAHA7RrP25eTkKCEhQYmJiWrWrJm+/PJLtW/fvqxqwy2mzsQVZX6Ow6/FlPk5AAAAcPMrcZCaPn26pk2bJrvdro8++qjYR/0AAAAA4FZQ4iA1ceJE+fn56Y477lBycrKSk5OL7bd06dJSKw4AAAAA3FGJg9TAgQOvOv05AAAAANwKShykkpKSyrAMAAAAACg/rmnWPgAAAAC4lRGkAAAAAMAQQQoAAAAADBGkAAAAAMAQQQoAAAAADBGkAAAAAMAQQQoAAAAADBGkAAAAAMCQS4PU1KlTdffddysgIEA1atRQnz59tHfvXqc+lmUpPj5eoaGh8vPzU8eOHbVr1y6nPvn5+Ro1apSqVasmf39/9e7dW0ePHr2RlwIAAADgFuLSIJWamqoRI0bom2++UUpKis6fP69u3brpzJkzjj7Tp0/XjBkzNHv2bG3evFl2u13R0dE6deqUo09sbKyWLVumJUuWaMOGDTp9+rR69uypCxcuuOKyAAAAANzkPF158pUrVzqtz58/XzVq1NDWrVvVoUMHWZalmTNnatKkSerbt68kKTk5WSEhIVq8eLGGDRumnJwczZs3TwsXLlTXrl0lSYsWLVJYWJjWrFmj7t273/DrAgAAAHBzc6t3pHJyciRJQUFBkqRDhw4pMzNT3bp1c/Tx8fFRVFSUNm3aJEnaunWrzp0759QnNDRUkZGRjj6Xys/PV25urtMCAAAAACXlNkHKsiyNHTtW9913nyIjIyVJmZmZkqSQkBCnviEhIY5tmZmZ8vb2VtWqVS/b51JTp05VYGCgYwkLCyvtywEAAABwE3ObIDVy5Eht375dH330UZFtNpvNad2yrCJtl7pSn7i4OOXk5DiW9PT0ay8cAAAAwC3HLYLUqFGj9Nlnn2ndunWqVauWo91ut0tSkZGlrKwsxyiV3W5XQUGBTp48edk+l/Lx8VHlypWdFgAAAAAoKZcGKcuyNHLkSC1dulRr165VRESE0/aIiAjZ7XalpKQ42goKCpSamqp27dpJklq2bCkvLy+nPhkZGdq5c6ejDwAAAACUJpfO2jdixAgtXrxYf//73xUQEOAYeQoMDJSfn59sNptiY2OVkJCgevXqqV69ekpISFDFihU1YMAAR9+hQ4dq3LhxCg4OVlBQkMaPH68mTZo4ZvEDAAAAgNLk0iA1d+5cSVLHjh2d2ufPn6/BgwdLkiZMmKC8vDwNHz5cJ0+eVOvWrbV69WoFBAQ4+r/55pvy9PRUv379lJeXpy5duigpKUkeHh436lIAAAAA3EJcGqQsy7pqH5vNpvj4eMXHx1+2j6+vrxITE5WYmFiK1QEAAABA8dxisgkAAAAAKE8IUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgyNPVBQAAgJtHnYkryvT4h1+LKdPjA0BJMSIFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIY8XV0AAABAaagzcUWZHv/wazFlenwA5QsjUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgyKVB6quvvlKvXr0UGhoqm82m5cuXO223LEvx8fEKDQ2Vn5+fOnbsqF27djn1yc/P16hRo1StWjX5+/urd+/eOnr06A28CgAAAAC3GpcGqTNnzuiuu+7S7Nmzi90+ffp0zZgxQ7Nnz9bmzZtlt9sVHR2tU6dOOfrExsZq2bJlWrJkiTZs2KDTp0+rZ8+eunDhwo26DAAAAAC3GE9XnrxHjx7q0aNHsdssy9LMmTM1adIk9e3bV5KUnJyskJAQLV68WMOGDVNOTo7mzZunhQsXqmvXrpKkRYsWKSwsTGvWrFH37t1v2LUAAAAAuHW47TtShw4dUmZmprp16+Zo8/HxUVRUlDZt2iRJ2rp1q86dO+fUJzQ0VJGRkY4+xcnPz1dubq7TAgAAAAAl5bZBKjMzU5IUEhLi1B4SEuLYlpmZKW9vb1WtWvWyfYozdepUBQYGOpawsLBSrh4AAADAzcxtg9RFNpvNad2yrCJtl7pan7i4OOXk5DiW9PT0UqkVAAAAwK3BbYOU3W6XpCIjS1lZWY5RKrvdroKCAp08efKyfYrj4+OjypUrOy0AAAAAUFJuG6QiIiJkt9uVkpLiaCsoKFBqaqratWsnSWrZsqW8vLyc+mRkZGjnzp2OPgAAAABQ2lw6a9/p06e1f/9+x/qhQ4eUlpamoKAg1a5dW7GxsUpISFC9evVUr149JSQkqGLFihowYIAkKTAwUEOHDtW4ceMUHBysoKAgjR8/Xk2aNHHM4gcAAAAApc2lQWrLli3q1KmTY33s2LGSpEGDBikpKUkTJkxQXl6ehg8frpMnT6p169ZavXq1AgICHPu8+eab8vT0VL9+/ZSXl6cuXbooKSlJHh4eN/x6AAAAANwaXBqkOnbsKMuyLrvdZrMpPj5e8fHxl+3j6+urxMREJSYmlkGFAAAAAFCU274jBQAAAADuiiAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFAAAAAIYIUgAAAABgyNPVBcC91Jm4oszPcfi1mDI/BwAAAFCWCFIAAADXqaz/RyT/ExJwPzzaBwAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGPF1dAAAAAK5NnYkryvwch1+LKfNzAOURI1IAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGCFIAAAAAYIggBQAAAACGPF1dAAAAAMqfOhNXlPk5Dr8WU+bnAK4VI1IAAAAAYIgRKQAAAJQrjIbBHTAiBQAAAACGCFIAAAAAYIhH+9wQw9UAAACAe2NECgAAAAAMMSIFAAAAlBBPDuEiRqQAAAAAwNBNMyI1Z84cvf7668rIyFDjxo01c+ZMtW/f3tVlAQAAAOUeI3FF3RRB6m9/+5tiY2M1Z84c3XvvvXr33XfVo0cP7d69W7Vr13Z1eQAAAMB1I8y4l5vi0b4ZM2Zo6NCheuqpp9SwYUPNnDlTYWFhmjt3rqtLAwAAAHATKvcjUgUFBdq6dasmTpzo1N6tWzdt2rSp2H3y8/OVn5/vWM/JyZEk5ebmll2hBgrzz5b5OS53rZz75jv3le7rW/HcN/OfNefm3LfCud3xe8WV576Z/6w5N+d2lYt1WJZ1xX4262o93NyxY8d02223aePGjWrXrp2jPSEhQcnJydq7d2+RfeLj4/XSSy/dyDIBAAAAlCPp6emqVavWZbeX+xGpi2w2m9O6ZVlF2i6Ki4vT2LFjHeuFhYXKzs5WcHDwZfcBLsrNzVVYWJjS09NVuXJlV5eDmxj3Gm4E7jPcKNxruBFK4z6zLEunTp1SaGjoFfuV+yBVrVo1eXh4KDMz06k9KytLISEhxe7j4+MjHx8fp7YqVaqUVYm4SVWuXJm/CHBDcK/hRuA+w43CvYYb4Xrvs8DAwKv2KfeTTXh7e6tly5ZKSUlxak9JSXF61A8AAAAASku5H5GSpLFjx+qJJ55Qq1at1LZtW7333ns6cuSInn32WVeXBgAAAOAmdFMEqf79++vEiRN6+eWXlZGRocjISP3zn/9UeHi4q0vDTcjHx0dTpkwp8ngoUNq413AjcJ/hRuFew41wI++zcj9rHwAAAADcaOX+HSkAAAAAuNEIUgAAAABgiCAFAAAAAIYIUgAAAABgiCAFlFB8fLxsNpvTYrfbXV0WyrmvvvpKvXr1UmhoqGw2m5YvX+603bIsxcfHKzQ0VH5+furYsaN27drlmmJRrl3tXhs8eHCR77g2bdq4pliUW1OnTtXdd9+tgIAA1ahRQ3369NHevXud+vC9hutVkvvsRnynEaQAA40bN1ZGRoZj2bFjh6tLQjl35swZ3XXXXZo9e3ax26dPn64ZM2Zo9uzZ2rx5s+x2u6Kjo3Xq1KkbXCnKu6vda5J0//33O33H/fOf/7yBFeJmkJqaqhEjRuibb75RSkqKzp8/r27duunMmTOOPnyv4XqV5D6Tyv477ab4HSngRvH09GQUCqWqR48e6tGjR7HbLMvSzJkzNWnSJPXt21eSlJycrJCQEC1evFjDhg27kaWinLvSvXaRj48P33G4LitXrnRanz9/vmrUqKGtW7eqQ4cOfK+hVFztPruorL/TGJECDOzbt0+hoaGKiIjQI488ooMHD7q6JNzEDh06pMzMTHXr1s3R5uPjo6ioKG3atMmFleFmtX79etWoUUP169fX008/raysLFeXhHIuJydHkhQUFCSJ7zWUjUvvs4vK+juNIAWUUOvWrbVgwQKtWrVK77//vjIzM9WuXTudOHHC1aXhJpWZmSlJCgkJcWoPCQlxbANKS48ePfTXv/5Va9eu1RtvvKHNmzerc+fOys/Pd3VpKKcsy9LYsWN13333KTIyUhLfayh9xd1n0o35TuPRPqCEfv9ITJMmTdS2bVvVrVtXycnJGjt2rAsrw83OZrM5rVuWVaQNuF79+/d3/HdkZKRatWql8PBwrVixwvEIFmBi5MiR2r59uzZs2FBkG99rKC2Xu89uxHcaI1LANfL391eTJk20b98+V5eCm9TF57ov/b+0WVlZRf5vLlDaatasqfDwcL7jcE1GjRqlzz77TOvWrVOtWrUc7XyvoTRd7j4rTll8pxGkgGuUn5+vPXv2qGbNmq4uBTepiIgI2e12paSkONoKCgqUmpqqdu3aubAy3ApOnDih9PR0vuNgxLIsjRw5UkuXLtXatWsVERHhtJ3vNZSGq91nxSmL7zQe7QNKaPz48erVq5dq166trKwsvfLKK8rNzdWgQYNcXRrKsdOnT2v//v2O9UOHDiktLU1BQUGqXbu2YmNjlZCQoHr16qlevXpKSEhQxYoVNWDAABdWjfLoSvdaUFCQ4uPj9dBDD6lmzZo6fPiwnn/+eVWrVk1/+MMfXFg1ypsRI0Zo8eLF+vvf/66AgADHyFNgYKD8/Pxks9n4XsN1u9p9dvr06RvznWYBKJH+/ftbNWvWtLy8vKzQ0FCrb9++1q5du1xdFsq5devWWZKKLIMGDbIsy7IKCwutKVOmWHa73fLx8bE6dOhg7dixw7VFo1y60r129uxZq1u3blb16tUtLy8vq3bt2tagQYOsI0eOuLpslDPF3WOSrPnz5zv68L2G63W1++xGfafZ/q8YAAAAAEAJ8Y4UAAAAABgiSAEAAACAIYIUAAAAABgiSAEAAACAIYIUAAAAABgiSAEAAACAIYIUAAAAABgiSAEAAACAIYIUAADlzODBg9WnTx9XlwEAtzSCFACgVGRlZWnYsGGqXbu2fHx8ZLfb1b17d3399deuLu2auENYOXz4sGw2m9LS0lxaBwCgKE9XFwAAuDk89NBDOnfunJKTk3X77bfr+PHj+vLLL5WdnV2m5y0oKJC3t3eZngMAgEsxIgUAuG6//vqrNmzYoGnTpqlTp04KDw/XPffco7i4OMXExDj6HTlyRA8++KAqVaqkypUrq1+/fjp+/Lhje3GjQLGxserYsaNjvWPHjho5cqTGjh2ratWqKTo6WpK0a9cuxcTEqHLlygoICFD79u114MABx37z589Xw4YN5evrqwYNGmjOnDnXdc27d+/WAw88oEqVKikkJERPPPGEfvnlF6c6n3vuOU2YMEFBQUGy2+2Kj493OsZ//vMf3XffffL19VWjRo20Zs0a2Ww2LV++XJIUEREhSWrevLlsNpvT5yBJf/nLX1SzZk0FBwdrxIgROnfu3HVdEwCg5AhSAIDrVqlSJVWqVEnLly9Xfn5+sX0sy1KfPn2UnZ2t1NRUpaSk6MCBA+rfv7/x+ZKTk+Xp6amNGzfq3Xff1U8//aQOHTrI19dXa9eu1datWzVkyBCdP39ekvT+++9r0qRJevXVV7Vnzx4lJCToxRdfVHJy8jVdb0ZGhqKiotSsWTNt2bJFK1eu1PHjx9WvX78idfr7++vbb7/V9OnT9fLLLyslJUWSVFhYqD59+qhixYr69ttv9d5772nSpElO+3/33XeSpDVr1igjI0NLly51bFu3bp0OHDigdevWKTk5WUlJSUpKSrqm6wEAmOPRPgDAdfP09FRSUpKefvppvfPOO2rRooWioqL0yCOPqGnTppJ+CwPbt2/XoUOHFBYWJklauHChGjdurM2bN+vuu+8u8fnuuOMOTZ8+3bH+/PPPKzAwUEuWLJGXl5ckqX79+o7tf/7zn/XGG2+ob9++kn4b6dm9e7feffddDRo0yPh6586dqxYtWighIcHR9uGHHyosLEw//PCD49xNmzbVlClTJEn16tXT7Nmz9eWXXyo6OlqrV6/WgQMHtH79etntdknSq6++6hhhk6Tq1atLkoKDgx19Lqpatapmz54tDw8PNWjQQDExMfryyy/19NNPG18PAMAcI1IAgFLx0EMP6dixY/rss8/UvXt3rV+/Xi1atHCMkuzZs0dhYWGOECVJjRo1UpUqVbRnzx6jc7Vq1cppPS0tTe3bt3eEqN/7+eeflZ6erqFDhzpGzipVqqRXXnnF6dE/E1u3btW6deucjtegQQNJcjrmxRB5Uc2aNZWVlSVJ2rt3r8LCwpwC0j333FPiGho3biwPD49ijw0AKHuMSAEASo2vr6+io6MVHR2tyZMn66mnntKUKVM0ePBgWZYlm81WZJ/ft1eoUEGWZTltL+69H39/f6d1Pz+/y9ZUWFgo6bfH+1q3bu207fdBxERhYaF69eqladOmFdlWs2ZNx39fGuxsNpujnst9HiV1pWMDAMoeQQoAUGYaNWrkmDihUaNGOnLkiNLT0x2jUrt371ZOTo4aNmwo6bdH2Xbu3Ol0jLS0tGJHmn6vadOmSk5O1rlz54r0DQkJ0W233aaDBw/qscceK5XratGihT799FPVqVNHnp7X9ldpgwYNdOTIER0/flwhISGSpM2bNzv1uTgb4YULF66vYABAqePRPgDAdTtx4oQ6d+6sRYsWOd6D+vjjjzV9+nQ9+OCDkqSuXbuqadOmeuyxx7Rt2zZ99913GjhwoKKiohyP6nXu3FlbtmzRggULtG/fPk2ZMqVIsCrOyJEjlZubq0ceeURbtmzRvn37tHDhQu3du1eSFB8fr6lTp+qtt97SDz/8oB07dmj+/PmaMWPGFY+bk5OjtLQ0p+XIkSMaMWKEsrOz9eijj+q7777TwYMHtXr1ag0ZMqTEoSc6Olp169bVoEGDtH37dm3cuNEx2cTFkaoaNWrIz8/PMZlFTk5OiY4NACh7BCkAwHWrVKmSWrdurTfffFMdOnRQZGSkXnzxRT399NOaPXu2JDmm9a5atao6dOigrl276vbbb9ff/vY3x3G6d++uF198URMmTNDdd9+tU6dOaeDAgVc9f3BwsNauXavTp08rKipKLVu21Pvvv+8YnXrqqaf0wQcfKCkpSU2aNFFUVJSSkpIc04tfzvr169W8eXOnZfLkyQoNDdXGjRt14cIFde/eXZGRkRo9erQCAwNVoULJ/mr18PDQ8uXLdfr0ad1999166qmn9MILL0j67RFJ6bdJPGbNmqV3331XoaGhjlAKAHA9m3Xpw+gAAMAlNm7cqPvuu0/79+9X3bp1XV0OAOAKCFIAALjIsmXLVKlSJdWrV0/79+/X6NGjVbVqVW3YsMHVpQEAroLJJgAAcJFTp05pwoQJSk9PV7Vq1dS1a1e98cYbri4LAFACjEgBAAAAgCEmmwAAAAAAQwQpAAAAADBEkAIAAAAAQwQpAAAAADBEkAIAAAAAQwQpAAAAADBEkAIAAAAAQwQpAAAAADD0/wF1DFUdFH+T1wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test best model\n",
    "test_predictions = test_best_model(best_config, best_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
